{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure AI Content Understanding - Classifier and Analyzer Demo\n",
    "\n",
    "This notebook demonstrates how to use Azure AI Content Understanding service to:\n",
    "1. Create a classifier to categorize documents\n",
    "2. Create a custom analyzer to extract specific fields\n",
    "3. Combine classifier and analyzers to classify, optionally split, and analyze documents in a flexible processing pipeline\n",
    "\n",
    "If you‚Äôd like to learn more before getting started, see the official documentation:\n",
    "[Understanding Classifiers in Azure AI Services](https://learn.microsoft.com/en-us/azure/ai-services/content-understanding/concepts/classifier)\n",
    "\n",
    "## Prerequisites\n",
    "1. Ensure Azure AI service is configured following [steps](../README.md#configure-azure-ai-service-resource)\n",
    "2. Install the required packages to run the sample.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import uuid\n",
    "from pathlib import Path\n",
    "\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Azure Content Understanding Client\n",
    "\n",
    "The `AzureContentUnderstandingClient` class handles all API interactions with the Azure AI service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from content_understanding_client import AzureContentUnderstandingClient\n",
    "    print(\"‚úÖ Azure Content Understanding Client imported successfully!\")\n",
    "except ImportError:\n",
    "    print(\"‚ùå Error: Make sure 'AzureContentUnderstandingClient.py' is in the same directory as this notebook.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configure Azure AI Service Settings and Prepare the Sample\n",
    "\n",
    "Update these settings to match your Azure environment:\n",
    "\n",
    "- **AZURE_AI_ENDPOINT**: Your Azure AI service endpoint URL or set up in \".env\" file\n",
    "- **AZURE_AI_API_VERSION**: The Azure AI API version to use. Default is \"2025-05-01-preview\". \n",
    "- **AZURE_AI_API_KEY**: Your Azure AI service key (optional if using token authentication)\n",
    "- **SAMPLE_CLAIMS_BUNDLE**: Path to the PDF document you want to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# always refresh all vars\n",
    "load_dotenv(override=True)\n",
    "# For authentication, you can use either token-based auth or subscription key, and only one of them is required\n",
    "AZURE_AI_ENDPOINT = os.getenv(\"AZURE_AI_ENDPOINT\")\n",
    "# IMPORTANT: Replace with your actual subscription key or set up in \".env\" file if not using token auth\n",
    "AZURE_AI_API_KEY = os.getenv(\"AZURE_CONTENT_UNDERSTANDING_SUBSCRIPTION_KEY\")\n",
    "AZURE_AI_API_VERSION = os.getenv(\"AZURE_AI_API_VERSION\", \"2025-05-01-preview\")\n",
    "SAMPLE_CLAIMS_BUNDLE = os.getenv(\"SAMPLE_CLAIMS_BUNDLE\")\n",
    "# Authentication - Using DefaultAzureCredential for token-based auth\n",
    "# Using the current users identity here\n",
    "# This will be a managed identity once move to an Azure Function\n",
    "\n",
    "# Setup credentials\n",
    "credential = DefaultAzureCredential(\n",
    "    exclude_managed_identity_credential=True,\n",
    "    exclude_client_secret_credential=True,\n",
    "    exclude_environment_credential=True,\n",
    "    exclude_workload_identity_credential=True,\n",
    "    exclude_shared_token_cache_credential=True,\n",
    "    exclude_azure_powershell_credential=True,\n",
    "    exclude_azure_developer_cli_credential=True,\n",
    ")\n",
    "token_provider = get_bearer_token_provider(credential, \"https://cognitiveservices.azure.com/.default\")\n",
    "\n",
    "file_location = Path(SAMPLE_CLAIMS_BUNDLE)\n",
    "\n",
    "print(\"üìã Configuration Summary:\")\n",
    "print(f\"   Endpoint: {AZURE_AI_ENDPOINT}\")\n",
    "print(f\"   API Version: {AZURE_AI_API_VERSION}\")\n",
    "#print(f\"   API KEY: {AZURE_AI_API_KEY}\")\n",
    "print(f\"   Document: {file_location.name if file_location.exists() else '‚ùå File not found'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define Classifier Schema\n",
    "\n",
    "The classifier schema defines:\n",
    "- **Categories**: Document types to classify (e.g., Legal, Medical)\n",
    "  - **description (Optional)**: An optional field used to provide additional context or hints for categorizing or splitting documents. This can be helpful when the category name alone isn‚Äôt descriptive enough. If the category name is already clear and self-explanatory, this field can be omitted.\n",
    "\n",
    "- **This classifier should indtify these document types**\n",
    "  -  **Completed_Claim_Form**  \n",
    "  -   **HIPAA_Release**  \n",
    "  -   **Signed_Physician_Statement**  \n",
    "  -   **Pathology_Report**  \n",
    "  -   **Doctor_Office_Visit_Report**  \n",
    "  -   **Scanner_Report**  \n",
    "  -   **Other_Document_Type**\n",
    "  -   **Itemized_Bill_for_Lab_Services**  \n",
    "  -   **Itemized_Bill_for_Radiology_Services**  \n",
    "  -   **Itemized_Bill_from_Other_Service_Providers_Type**  \n",
    "  -   **UB04_Bil** \n",
    "\n",
    "- **splitMode Options**: Defines how multi-page documents should be split before classification or analysis.\n",
    "  - `\"auto\"`: Automatically split based on content.  \n",
    "  For example, if two categories are defined as ‚Äúinvoice‚Äù and ‚Äúapplication form‚Äù:\n",
    "    - A PDF with only one invoice will be classified as a single document.\n",
    "    - A PDF containing two invoices and one application form will be automatically split into three classified sections.\n",
    "  - `\"none\"`: No splitting.  \n",
    "  The entire multi-page document is treated as a single unit for classification and analysis.\n",
    "  - `\"perPage\"`: Split by page.  \n",
    "  Each page is treated as a separate document. This is useful when you‚Äôve built custom analyzers designed to operate on a per-page basis.\n",
    "\n",
    "  ### Below is my schema definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am automatically split based on content! That means per document within the bundle\n",
    "# Define field descriptionsand classifier document categories and their descriptions\n",
    "classifier_schema = {\n",
    "\t\t\t\"categories\": {\n",
    "\t\t\t\t\t\"Completed_Claim_Form\": {\"description\": \"a Completed Claim Form\"},\n",
    "\t\t\t\t\t\"HIPAA_Release\": {\"description\": \"a HIPAA Release\"},\n",
    "\t\t\t\t\t\"Signed_Physician_Statement\": {\"description\": \"a Signed Physician Statement\"},\n",
    "                    \"Itemized_Bill_for_Lab_Services\": {\"description\": \"an Itemized Bill from a laboratory for Lab test and services. This type which includes Statments, Invoices, Account Summaries, any document that has dollar amounts on it sent from a lab\"},\n",
    "\t\t\t\t\t\"Itemized_Bill_for_Radiology_Services\": {\"description\": \"an Itemized Bill from a radiology department for imaging services. This type which includes Statments, Invoices, Account Summaries, any document that has dollar amounts on it sent from a radiology provider.\"},\n",
    "                    \"Itemized_Bill_from_Other_Service_Providers_Type\": {\"description\": \"an Itemized Bill from a other than a laboratory, a radiology provider or a hospitals provider types listed above This type which includes Statments, Invoices, Account Summaries, any document that has dollar amounts on it.\"},\n",
    "\t\t\t\t\t\"UB04_Bill\": {\"description\": \"A special type of itemized bill. It will have the notation on it UB04 or UB-04 or UB 04.\"},\n",
    "\t\t\t\t\t\"Pathology_Report\": {\"description\": \"a Pathology Report\"},\n",
    "                    \"Doctor_Office_Visit_Report\": {\"description\": \"a Doctor Office Visit Report contains a narrative of the visit, including symptoms, diagnosis, and treatment plan. It does not include any billing information.\"},\n",
    "                    \"Scanner_Report\": {\"description\": \"a Scanner Report that list issue with the scan of the documents\"},\n",
    "\t\t\t\t\t\"Other_Document_Type\": {\"description\": \"A document type other the other ones specified\"}\n",
    "\t\t\t\t\t},\n",
    "    \t\t\t\"splitMode\": \"auto\"  # IMPORTANT: Automatically detect document boundaries. Can change mode for your needs.\n",
    "\t\t\t}\n",
    "\t\t\t\n",
    "\n",
    "# Make 2 columns in the output columns aligned\n",
    "print(\"üìÑ Classifier DocTypes:\")\n",
    "for category, details in classifier_schema[\"categories\"].items():\n",
    "    print(f\"   ‚Ä¢ {category}: {details['description'][:60]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Initialize Content Understanding Client\n",
    "\n",
    "Create the client that will communicate with Azure AI services.\n",
    "\n",
    "‚ö†Ô∏è Important:\n",
    "You must update the code below to match your Azure authentication method.\n",
    "Look for the `# IMPORTANT` comments and modify those sections accordingly.\n",
    "If you skip this step, the sample may not run correctly.\n",
    "\n",
    "‚ö†Ô∏è Note: Using a subscription key works, but using a token provider with Azure Active Directory (AAD) is much safer and is highly recommended for production environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Azure Content Understanding client\n",
    "try:\n",
    "    content_understanding_client = AzureContentUnderstandingClient(\n",
    "        endpoint=AZURE_AI_ENDPOINT,\n",
    "        api_version=AZURE_AI_API_VERSION,\n",
    "        # IMPORTANT: Comment out token_provider if using subscription key\n",
    "        token_provider=token_provider,\n",
    "        # IMPORTANT: Uncomment this if using subscription key\n",
    "        subscription_key=AZURE_AI_API_KEY,\n",
    "    )\n",
    "    print(\"‚úÖ Content Understanding client initialized successfully!\")\n",
    "    print(\"   Ready to create classifiers and analyzers.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to initialize client: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9A. Create a Custom Analyzer (9A) for the itemizated bill doc types\n",
    "\n",
    "Now let's create a schenma for custom analyzer that can extract specific fields from documents.\n",
    "This analyzer will:\n",
    "- Extract common document fields from the Medical and billing documents in the bundle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define analyzer schema with custom fields\n",
    "analyzer_schema_9A = {\n",
    "    \"description\": \"Analyzer_with_document_fields - extracts key document information from a bundle of documents in a single pdf submitted for claims\",\n",
    "    \"baseAnalyzerId\": \"prebuilt-documentAnalyzer\",  # Built on top of the general document analyzer\n",
    "    \"config\": {\n",
    "        \"returnDetails\": True,\n",
    "        \"enableLayout\": True,          # Extract layout information\n",
    "        \"enableBarcode\": False,        # Skip barcode detection\n",
    "        \"enableFormula\": False,        # Skip formula detection\n",
    "        \"estimateFieldSourceAndConfidence\": True, # Set to True if you want to estimate the field location (aka grounding) and confidence\n",
    "        \"disableContentFiltering\": False,\n",
    "    },\n",
    "    \"fieldSchema\": {\n",
    "        \"fields\": {\n",
    "\t\t\t\"title_on_first_page_of_document\": {\n",
    "\t\t\t\t\"type\": \"string\",\n",
    "\t\t\t\t\"method\": \"generate\",\n",
    "\t\t\t\t\"description\": \"This is the title of the document. It will typically be the line of text with the largest sized font near the top of the page The value should be \\\"None\\\" if there is no title or it cannot be determined. \"\n",
    "\t\t\t}\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Generate unique analyzer ID\n",
    "analyzer_id_9A = \"Analyzer_with_document_fields_9A_\" + str(uuid.uuid4())\n",
    "\n",
    "# Create the analyzer\n",
    "try:\n",
    "    print(f\"üî® Creating custom analyzer: {analyzer_id_9A}\")\n",
    "    print(\"\\nüìã Analyzer will extract:\")\n",
    "    for field_name, field_info in analyzer_schema_9A[\"fieldSchema\"][\"fields\"].items():\n",
    "        print(f\"   ‚Ä¢ {field_name}: {field_info['description']}\")\n",
    "    \n",
    "    response = content_understanding_client.begin_create_analyzer(analyzer_id_9A, analyzer_schema_9A)\n",
    "    result = content_understanding_client.poll_result(response)\n",
    "    \n",
    "    print(\"\\n‚úÖ Analyzer_with_document_fields created successfully!\")\n",
    "    print(f\"   Analyzer ID 9A: {analyzer_id_9A}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error creating analyzer: {e}\")\n",
    "    analyzer_id_9A = None  # Set to None if creation failed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9B. And a Custom Analyzer (9B) for the billed expenses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define analyzer schema with custom fields\n",
    "analyzer_schema_9B = {\n",
    "    \"description\": \"Analyzer_with_document_fields - extracts key document information from a bundle of documents in a single pdf submitted for claims\",\n",
    "    \"baseAnalyzerId\": \"prebuilt-documentAnalyzer\",  # Built on top of the general document analyzer\n",
    "    \"config\": {\n",
    "        \"returnDetails\": True,\n",
    "        \"enableLayout\": True,          # Extract layout information\n",
    "        \"enableBarcode\": False,        # Skip barcode detection\n",
    "        \"enableFormula\": False,        # Skip formula detection\n",
    "        \"estimateFieldSourceAndConfidence\": True, # Set to True if you want to estimate the field location (aka grounding) and confidence\n",
    "        \"disableContentFiltering\": False,\n",
    "    },\n",
    "    \"fieldSchema\": {\n",
    "        \"fields\": {\n",
    "\t\t\t\"title_on_first_page_of_document\": {\n",
    "\t\t\t\t\"type\": \"string\",\n",
    "\t\t\t\t\"method\": \"generate\",\n",
    "\t\t\t\t\"description\": \"This is the title of the document. It will typically be the line of text with the largest sized font near the top of the page The value should be \\\"None\\\" if there is no title or it cannot be determined. \"\n",
    "\t\t\t},\n",
    "\t\t\t\"Expenses\": {\n",
    "\t\t\t\t\"type\": \"array\",\n",
    "\t\t\t\t\"items\": {\n",
    "\t\t\t\t\t\"type\": \"object\",\n",
    "\t\t\t\t\t\"properties\": {\n",
    "                        \"Expense_Amount\": {\n",
    "                                \"type\": \"number\",\n",
    "                                \"method\": \"generate\",\n",
    "                                \"description\": \"A table of the expense items amounts billed to patient or insurance company. These are charges for procedures, professional services, lab tests performed and other medical services. They will be numeric with 2 decimal places. Keep the 2 decimal places even it they are .00. They will typically be on the document pages in a tabular layout with the expensed dollar amounts all in the same column. You will typically find the other columns to extract ICD code CPT code etc for the other columns in this table usually on the same line as the amount. Only capture positive amounts that are actual charges (not totals, subtotals, adjustments, refunds, or negative values or amount that are zero). All dollar amounts for expenses must be captured. the document may contain multiple pages of expenses within a single document.\"\n",
    "                            },\n",
    "                            \"ICD_Code\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"method\": \"generate\",\n",
    "                                \"description\": \"The ICD code associated with the expense if there is one. If there is no ICD code, use \\\"\\\".  The ICD code is usually on the same line of the table as the amount\"\n",
    "                            },\n",
    "                            \"Date\": {\n",
    "                                \"type\": \"date\",\n",
    "                                \"method\": \"generate\",\n",
    "                                \"description\": \"The date of the expense. The date is usually on the same line of the table as the amount format the date as mm/dd/yyyy.\"\n",
    "                            },\n",
    "                            \"Expense_Description\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"method\": \"generate\",\n",
    "                                \"description\": \"The description of the expense. This may be the procedure name. It is usually on the same line of the table as the amount.\"\t\n",
    "                            },\n",
    "                            \"Surgeon_Name_or_Provider\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"method\": \"generate\",\n",
    "                                \"description\": \"The surgeon or provider if this expense was a sugical procedure.\"\n",
    "                            },\n",
    "                            \"CPT_Code\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"method\": \"generate\",\n",
    "                                \"description\": \"The CPT code associated with the expense.  It is usually on the same line of the table as the amount.\"\t\n",
    "                            },\n",
    "                            \"Ref_Page\": {\n",
    "                                \"type\": \"number\",\n",
    "                                \"method\": \"generate\",\n",
    "                                \"description\": \"The Bundle page the expense was found on. This is the page number from the top of the page in tha stamped header. It will on the line of text that starts with Page XX of YY where xx  is the current page number and yy is the total number of pages in the document bundle.\"\n",
    "                            },\n",
    "                            \"Drug_Name\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"method\": \"generate\",\n",
    "                                \"description\": \"If the expense charge was for a drug, put the drug name here. If not for a drug put N/A in this field.\"\n",
    "                            },\n",
    "                            \"Expense_Type\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"method\": \"generate\",\n",
    "                                \"description\": \"Categorize each expense into one of four categories based on the description, ICD10, CPT code, or other context. The 4 categories are:  1. Cancer_History_Expenses, 2. Diagnostic_Tests_and_Labs_Expenses,  3. Surgical_Events_Expenses,  4. Cancer_Treatment_Expenses. Put every expense into one of the four. If it was for a exam, a lab test or other diagostic test that diagosed cancer or remission, make it a #1. it was for a lab or dignostic test make it a #2 If it was for a surgical procedure make it a #3. Everything else is a #4. use the full name not just the number when filling in field.\"\n",
    "                            }\n",
    "                        },\n",
    "                        \"method\": \"generate\"\n",
    "                    },\n",
    "\t\t\t\t\"method\": \"generate\",\n",
    "\t\t\t\t\"description\": \"Expenses are charges billed to either the patient or insurance company. They are single charges for a procedure, test or other medical service. They do not include payments, adjustments, refunds, total balances, subtotals. Other than these exceptions all other dollar amounts may be an expense and should be reviewed.\"\n",
    "                }\n",
    "            },\n",
    "        }\n",
    "}\n",
    "\n",
    "# Generate unique analyzer ID\n",
    "analyzer_id_9B = \"Analyzer_with_document_fields_9B_\" + str(uuid.uuid4())\n",
    "\n",
    "# Create the analyzer\n",
    "try:\n",
    "    print(f\"üî® Creating custom analyzer: {analyzer_id_9B}\")\n",
    "    print(\"\\nüìã Analyzer will extract:\")\n",
    "    for field_name, field_info in analyzer_schema_9B[\"fieldSchema\"][\"fields\"].items():\n",
    "        print(f\"   ‚Ä¢ {field_name}: {field_info['description']}\")\n",
    "\n",
    "    response = content_understanding_client.begin_create_analyzer(analyzer_id_9B, analyzer_schema_9B)\n",
    "    result = content_understanding_client.poll_result(response)\n",
    "    \n",
    "    print(\"\\n‚úÖ Analyzer_with_document_fields created successfully!\")\n",
    "    print(f\"   Analyzer ID: {analyzer_id_9B}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error creating analyzer: {e}\")\n",
    "    analyzer_id_9B = None  # Set to None if creation failed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9C. And a Custom Analyzer (9C) for the patient information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define analyzer schema with custom fields\n",
    "analyzer_schema_9C = {\n",
    "    \"description\": \"Analyzer_with_document_fields - extracts key document information from a bundle of documents in a single pdf submitted for claims\",\n",
    "    \"baseAnalyzerId\": \"prebuilt-documentAnalyzer\",  # Built on top of the general document analyzer\n",
    "    \"config\": {\n",
    "        \"returnDetails\": True,\n",
    "        \"enableLayout\": True,          # Extract layout information\n",
    "        \"enableBarcode\": False,        # Skip barcode detection\n",
    "        \"enableFormula\": False,        # Skip formula detection\n",
    "        \"estimateFieldSourceAndConfidence\": True, # Set to True if you want to estimate the field location (aka grounding) and confidence\n",
    "        \"disableContentFiltering\": False,\n",
    "    },\n",
    "    \"fieldSchema\": {\n",
    "        \"fields\": {\n",
    "\t\t\t\"title_on_first_page_of_document\": {\n",
    "\t\t\t\t\"type\": \"string\",\n",
    "\t\t\t\t\"method\": \"generate\",\n",
    "\t\t\t\t\"description\": \"This is the title of the document. It will typically be the line of text with the largest sized font near the top of the page The value should be \\\"None\\\" if there is no title or it cannot be determined. \"\n",
    "\t\t\t},\n",
    "\t\t\t\"Patient_First_Name\": {\n",
    "                \"type\": \"string\",\n",
    "                \"method\": \"generate\",\n",
    "                \"description\": \"The first name of the patient. This is usually on the first page of the document.\"\n",
    "            },\n",
    "            \"Patient_Last_Name\": {\n",
    "                \"type\": \"string\",\n",
    "                \"method\": \"generate\",\n",
    "                \"description\": \"The last name of the patient. This is usually on the first page of the document.\"\n",
    "            },\n",
    "            \"DOB\": {\n",
    "                \"type\": \"string\",\n",
    "                \"method\": \"generate\",\n",
    "                \"description\": \"The DOB of the patient. This is usually on the first page of the document. Put into YYYY-MM-DD format.\"\n",
    "            },\n",
    "            \"Gender\": {\n",
    "                \"type\": \"string\",\n",
    "                \"method\": \"generate\",\n",
    "                \"description\": \"The gender of the patient. This is usually on the first page of the document.\"\n",
    "            },\n",
    "            \"Policy_Number\": {\n",
    "                \"type\": \"string\",\n",
    "                \"method\": \"generate\",\n",
    "                \"description\": \"The policy number of the patient. This is usually on the first page of the document. If the field is missing, use \\\"\\\".\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Generate unique analyzer ID\n",
    "analyzer_id_9C = \"Analyzer_with_document_fields_9C_\" + str(uuid.uuid4())\n",
    "\n",
    "# Create the analyzer\n",
    "try:\n",
    "    print(f\"üî® Creating custom analyzer: {analyzer_id_9C}\")\n",
    "    print(\"\\nüìã Analyzer will extract:\")\n",
    "    for field_name, field_info in analyzer_schema_9C[\"fieldSchema\"][\"fields\"].items():\n",
    "        print(f\"   ‚Ä¢ {field_name}: {field_info['description']}\")\n",
    "\n",
    "    response = content_understanding_client.begin_create_analyzer(analyzer_id_9C, analyzer_schema_9C)\n",
    "    result = content_understanding_client.poll_result(response)\n",
    "    \n",
    "    print(\"\\n‚úÖ Analyzer_with_document_fields created successfully!\")\n",
    "    print(f\"   Analyzer ID: {analyzer_id_9C}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error creating analyzer: {e}\")\n",
    "    analyzer_id_9C = None  # Set to None if creation failed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Create an Enhanced Classifier with 3 Custom Analyzers  - Create the Schema\n",
    "\n",
    "Now we'll create a new classifier that classifys the document and our 3 custom analyzer, 1 for bills and 1 for claim form and 1 everything else. This combines classification with field extraction in one operation.\n",
    "\n",
    "\n",
    "we are using the 3 analyzers from previos cells 9A, 9B and 9C\n",
    "\n",
    "\n",
    "## This is the schema for my Classifier  \n",
    "\n",
    "Not that for each document type I am specifing one of the 3 analyzers 9A or 9B or 9C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am automatically split based on content! That means per document within the bundle\n",
    "# Define field descriptionsand classifier document categories and their descriptions\n",
    "enhanced_classifier_with_document_metadata_and_fields_schema_9 = {\n",
    "\t\t\t\"categories\": {\n",
    "                \t\"Completed_Claim_Form\": {\"description\": \"a Completed Claim Form\", \"analyzerId\": analyzer_id_9C},\n",
    "\t\t\t\t\t\"HIPAA_Release\": {\"description\": \"a HIPAA Release\", \"analyzerId\": analyzer_id_9A},\n",
    "\t\t\t\t\t\"Signed_Physician_Statement\": {\"description\": \"a Signed Physician Statement\", \"analyzerId\": analyzer_id_9A},\n",
    "                    \"Pathology_Report\": {\"description\": \"a Pathology Report\", \"analyzerId\": analyzer_id_9A},\n",
    "                    \"Doctor_Office_Visit_Report\": {\"description\": \"a Doctor Office Visit Report contains a narrative of the visit, including symptoms, diagnosis, and treatment plan. It does not include any billing information.\", \"analyzerId\": analyzer_id_9A},\n",
    "                    \"Scanner_Report\": {\"description\": \"a Scanner Report that list issue with the scan of the documents\", \"analyzerId\": analyzer_id_9A},\n",
    "\t\t\t\t\t\"Other_Document_Type\": {\"description\": \"A document type other the other ones specified\", \"analyzerId\": analyzer_id_9A},\n",
    "\t\t\t\t\t\"Itemized_Bill_for_Lab_Services\": {\"description\": \"an Itemized Bill from a laboratory for Lab test and services. This type which includes Statments, Invoices, Account Summaries, any document that has dollar amounts on it sent from a lab\", \"analyzerId\": analyzer_id_9B},\n",
    "\t\t\t\t\t\"Itemized_Bill_for_Radiology_Services\": {\"description\": \"an Itemized Bill from a radiology department for imaging services. This type which includes Statments, Invoices, Account Summaries, any document that has dollar amounts on it sent from a radiology provider.\", \"analyzerId\": analyzer_id_9B},\n",
    "                    \"Itemized_Bill_from_Other_Service_Providers_Type\": {\"description\": \"an Itemized Bill from a other than a laboratory, a radiology provider or a hospitals provider types listed above This type which includes Statments, Invoices, Account Summaries, any document that has dollar amounts on it.\", \"analyzerId\": analyzer_id_9B},\n",
    "\t\t\t\t\t\"UB04_Bill\": {\"description\": \"A special type of itemized bill. It will have the notation on it UB04 or UB-04 or UB 04.\", \"analyzerId\": analyzer_id_9B},\n",
    "\t\t\t\t\t},\n",
    "    \t\t\t\"splitMode\": \"auto\"  # IMPORTANT: Automatically detect document boundaries. Can change mode for your needs.\n",
    "\t\t\t}\n",
    "# Make 2 columns in the output columns aligned\n",
    "print(\"üìÑ Classifier DocTypes:\")\n",
    "for category, details in enhanced_classifier_with_document_metadata_and_fields_schema_9[\"categories\"].items():\n",
    "    print(f\"   ‚Ä¢ {category}: {details['description'][:60]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Then, create the Classifier  \n",
    "\n",
    "It take the schema ans an input parameter and the name you want to give to the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Using analyzer from prior cell 9A:: {analyzer_id_9A}\")\n",
    "print(f\"Using analyzer from prior cell 9B:: {analyzer_id_9B}\")\n",
    "print(f\"Using analyzer from prior cell 9C:: {analyzer_id_9C}\")\n",
    "\n",
    "\n",
    "# Generate unique enhanced classifier ID\n",
    "classifier_id_9 = \"classifier_based_on_doc_type_9\" + str(uuid.uuid4())\n",
    "print(f\"üî® Creating classifier: {classifier_id_9}\")\n",
    "\n",
    "# Create the enhanced classifier\n",
    "if analyzer_id_9A and analyzer_id_9B:  # Only create if both of the previous analyzers was successfully created\n",
    "\tprint(\"\\nüìã Configuration:\")\n",
    "\tprint(\"   ‚Ä¢ Medical documents in claim bundle ‚Üí Custom analyzer with field extraction\")\n",
    "\n",
    "\tprint(f\"\\n   ‚Ä¢ These document types below can use the classifier {classifier_id_9} and the custom analyzer - analyzer_id: {analyzer_id_9C} and this schema:  enhanced_classifier_with_document_metadata_and_fields_schema_9\")\n",
    "\tprint(\"\\n\t- Completed_Claim_Form\")\n",
    "\n",
    "\n",
    "\tprint(f\"\\n   ‚Ä¢ These document types below can use the classifier {classifier_id_9} and the custom analyzer - analyzer_id: {analyzer_id_9A} and this schema:  enhanced_classifier_with_document_metadata_and_fields_schema_9\")\n",
    "\tprint(\"\t\t- HIPAA_Release\")\n",
    "\tprint(\"\t\t- Signed_Physician_Statement\")\n",
    "\tprint(\"\t\t- Pathology_Report\")\n",
    "\tprint(\"\t\t- Doctor_Office_Visit_Report\")\n",
    "\tprint(\"\t\t- Scanner_Report\")\n",
    "\tprint(\"\t\t- Other_Document_Type\")\n",
    "\n",
    "\tprint(f\"\\n   ‚Ä¢ These document types below can use the classifier {classifier_id_9} and the custom analyzer - analyzer_id: {analyzer_id_9B} and this schema: enhanced_classifier_with_document_metadata_and_fields_schema_9\")\n",
    "\tprint(f\"\\n\t- Itemized_Bill_for_Lab_Services\")\n",
    "\tprint(f\"\t- Itemized_Bill_for_Radiology_Services\")\n",
    "\tprint(f\"\t- Itemized_Bill_from_Other_Service_Providers_Type\")\n",
    "\tprint(f\"\t- UB04_Bill\")\n",
    "\ttry:\n",
    "\t\tresponse = content_understanding_client.begin_create_classifier(classifier_id_9, enhanced_classifier_with_document_metadata_and_fields_schema_9 )\n",
    "\t\tresult = content_understanding_client.poll_result(response)\n",
    "\t\t\t\n",
    "\t\tprint(\"\\n‚úÖ Enhanced classifier created successfully!\")\n",
    "\t\t\t\n",
    "\texcept Exception as e:\n",
    "\t\tprint(f\"\\n‚ùå Error creating enhanced classifier: {e}\")\n",
    "else:\n",
    "\tprint(\"‚ö†Ô∏è  Skipping enhanced classifier creation - analyzer was not created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Process Document with Enhanced Classifier - this is reading the PDF document\n",
    "\n",
    "Let's process the documents again using our enhanced classifier.  \n",
    "\n",
    "All documents will now have additional metadata fields extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the classifyer that breaks the bundle into documents\n",
    "#print(f\"Using analyzer from prior cell 9A:: {analyzer_id_9A}\")\n",
    "print(f\"Using analyzer from prior cell 9B:: {analyzer_id_9B}\")\n",
    "if classifier_id_9:\n",
    "    print(f\"üî® Using classifier: {classifier_id_9}\")\n",
    "if analyzer_id_9A and analyzer_id_9B and analyzer_id_9C:\n",
    "    print(f\"üî® Using analyzer: {analyzer_id_9A} and {analyzer_id_9B}  and {analyzer_id_9C}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Skipping analyzer usage - analyzer was not created successfully in previous cell\")\n",
    "if classifier_id_9 and analyzer_id_9A and analyzer_id_9B and analyzer_id_9C:\n",
    "    print(f\"üî® Using classifier: {classifier_id_9}\")\n",
    "    try:\n",
    "        # Check if document exists\n",
    "        if not file_location.exists():\n",
    "            raise FileNotFoundError(f\"Document not found at {file_location}\")\n",
    "    \n",
    "        # Process with enhanced classifier\n",
    "        print(\"üìÑ Processing document with enhanced classifier\")\n",
    "        print(f\"   Document: {file_location.name}\")\n",
    "        print(\"\\n‚è≥ Processing with classification + field extraction...\")\n",
    "\n",
    "        response = content_understanding_client.begin_classify(classifier_id=classifier_id_9, file_location=str(file_location))\n",
    "        enhanced_result = content_understanding_client.poll_result(response, timeout_seconds=720,polling_interval_seconds=25)\n",
    "        \n",
    "        print(\"\\n‚úÖ Enhanced processing completed!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error processing document: {e}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Skipping enhanced classification - enhanced classifier was not created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. View Enhanced Results with Extracted Fields  - Now we can look at what was extracted\n",
    "\n",
    "Let's see the classification results along with the extracted fields. \n",
    "-  All documents should have a classification\n",
    "-  All documents should have a title (if one could be found)\n",
    "-  The itemized bills should have extracted expenses.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display enhanced results\n",
    "if 'enhanced_result' in locals() and enhanced_result:\n",
    "    result_data = enhanced_result.get(\"result\", {})\n",
    "    contents = result_data.get(\"contents\", [])\n",
    "    \n",
    "    print(\"üìä ENHANCED CLASSIFICATION RESULTS WITH DOCUMENT METADATA\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"\\nTotal sections(documents) found: {len(contents)}\")\n",
    "    \n",
    "    # Process each section\n",
    "    for i, content in enumerate(contents, 1):\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"DOCUMENT #{i}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        category = content.get('category', 'Unknown')\n",
    "\n",
    "    \n",
    "        print(f\"\\nüìÅ Type of Document: {category}\")\n",
    "        print(f\"üìÑ Document Starting Page in Bundle: {content.get('startPageNumber', '?')}\")\n",
    "        print(f\"üìÑ Document Ending Page in Bundle: {content.get('endPageNumber', '?')}\")\n",
    "        print(f\"üìÑ Number of Pages in Document: {content.get('endPageNumber', 0) - content.get('startPageNumber', 0) + 1}\")\n",
    "\n",
    " \n",
    "        \n",
    "\n",
    "        # Show extracted fields from field extraction\n",
    "        fields = content.get('fields', {})\n",
    "        if fields:\n",
    "            for field_name, field_data in fields.items():\n",
    "                if field_name == \"title_on_first_page_of_document\":\n",
    "                    print(f\"üìÑ Document Title: {field_data['valueString']}\")\n",
    "                    continue\n",
    "\n",
    "                if field_name == 'Patient_First_Name':\n",
    "                    print(f\"üìÑ Patient_First_Name: {field_data['valueString']}\")\n",
    "                    continue\n",
    "\n",
    "                if field_name == \"Patient_Last_Name\":\n",
    "                    print(f\"üìÑ Patient_Last_Name: {field_data['valueString']}\")\n",
    "                    continue\n",
    "\n",
    "                if field_name == \"DOB\":\n",
    "                    print(f\"üìÑ DOB: {field_data['valueString']}\")\n",
    "                    continue\n",
    "\n",
    "                if field_name == \"Gender\":\n",
    "                    print(f\"üìÑ Gender: {field_data['valueString']}\")\n",
    "                    continue\n",
    "\n",
    "                if field_name == \"Policy_Number\":\n",
    "                    print(f\"üìÑ Policy_Number: {field_data['valueString']}\")\n",
    "                    continue\n",
    "\n",
    "                if field_name == \"Expenses\":\n",
    "                    for expense in field_data.get('valueArray', []):\n",
    "                        print(expense)\n",
    "                else:\n",
    "                    print(field_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. View Enhanced Results with Extracted Fields - Another way to view it, it is just JSON\n",
    "\n",
    "Let's see the classification results along with the extracted fields from the documents in the claim document bundle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also see the fulll JSON result below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(enhanced_result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Summary and Next Steps\n",
    "\n",
    "Congratulations! You've successfully:\n",
    "1. ‚úÖ Created a basic classifier to categorize documents\n",
    "2. ‚úÖ Created a 3 custom analyzers to extract specific fields from specific types of documents\n",
    "3. ‚úÖ Combined them into an enhanced classifier for intelligent document processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Let's count the expenses found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I need a count of expenses found\n",
    "if 'enhanced_result' in locals() and enhanced_result:\n",
    "    result_data = enhanced_result.get(\"result\", {})\n",
    "    contents = result_data.get(\"contents\", [])\n",
    "\n",
    "    expense_count = 0\n",
    "    for content in contents:\n",
    "        fields = content.get('fields', {})\n",
    "        if fields:\n",
    "            expense_count += len(fields.get(\"Expenses\", {}).get('valueArray', []))\n",
    "\n",
    "    print(f\"üí∞ Total expenses found: {expense_count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
